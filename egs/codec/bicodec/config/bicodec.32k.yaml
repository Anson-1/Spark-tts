#===========================|  Dataset Configuration |==========================#
datasets:
  _target_: sparkvox.models.base.dataloaders.base_datamodule_pl.BaseDataModule
  _recursive_: false
  jsonlfiles:
    train:
      - /aifs4su/xinshengwang/data/speech/32k/emilia_en.jsonl
      - /aifs4su/xinshengwang/data/speech/32k/emilia_zh.jsonl
      - /aifs4su/xinshengwang/data/speech/32k/emns.jsonl
      - /aifs4su/xinshengwang/data/speech/32k/expresso.jsonl
      - /aifs4su/xinshengwang/data/speech/32k/hifi_tts.jsonl
      - /aifs4su/xinshengwang/data/speech/32k/vctk_train.jsonl
    val:
      - /aifs4su/xinshengwang/data/speech/32k/vctk_val.jsonl

  highpass_cutoff_freq: 40
  sample_rate: 32000
   sample_rate_for_ssl: 16000
  segment_duration: 2.4 # (s)
  max_val_duration: 12 # (s)
  latent_hop_length: 640
  ref_segment_duration: 6 # (s)
  additonal_duration_per_side: 1 # (s)
  volume_normalize: true 

  dataloader:
    _target_: sparkvox.models.codec.BiCodec.dataloaders.wav_XLSR_dataset.BicodecDataset
    batch_size: 24
    val_batch_size: 1
    num_workers: 8

#===========================|  Model Configuration |============================#

model:
  _target_: sparkvox.models.codec.BiCodec.lightning_models.bicodec.BiCodec
  _recursive_: false
  checkpoint: null    
  ignore_keys: []
  log_interval: 100
  syn_interval: 2000
  sample_rate: 32000
  additonal_duration_per_side: 1

  sslmodel:
    _target_:  sparkvox.models.codec.BiCodec.modules.wav2vec.Wav2Vec
    model_dir: 'pretrained_models/wav2vec2-large-xlsr-53'

  generator:
    _target_: sparkvox.models.codec.BiCodec.modules.generator.Generator
    _recursive_: True

    mel_params:
      sample_rate: 32000
      n_fft: 1024
      win_length: 640
      hop_length: 320
      mel_fmin: 10 
      mel_fmax: null
      num_mels: 128

    encoder:
      _target_: sparkvox.models.codec.BiCodec.modules.feat_encoder.Encoder
      input_channels: 1024
      vocos_dim: 384
      vocos_intermediate_dim: 2048
      vocos_num_layers: 12
      out_channels: 1024
      sample_ratios: [1,1]

    decoder:
      _target_: sparkvox.models.codec.base.modules.wave_generator_dac.Decoder
      input_channel: 1024
      channels: 1536
      rates: [8, 5, 4, 4]
      kernel_sizes: [16, 11, 8, 8]

    quantizer:
      _target_: sparkvox.models.codec.base.quantize.factorized_vector_quantize.FactorizedVectorQuantize
      input_dim: 1024
      codebook_size: 8192
      codebook_dim: 8
      commitment: 0.25
      codebook_loss_weight: 4.0
      use_l2_normlize: True
      threshold_ema_dead_code: 0.2
    
    speaker_encoder:
      _target_: sparkvox.models.codec.BiCodec.modules.speaker_encoder.SpeakerEncoder
      input_dim: 128
      out_dim: 1024
      latent_dim: 128
      token_num: 32
      fsq_levels: [4, 4, 4, 4, 4, 4]
      fsq_num_quantizers: 1

    prenet:
      _target_: sparkvox.models.codec.BiCodec.modules.feat_decoder.Decoder
      input_channels: 1024
      vocos_dim: 384
      vocos_intermediate_dim: 2048
      vocos_num_layers: 12
      out_channels: 1024
      condition_dim: 1024
      sample_ratios: [1,1]
      use_tanh_at_final: False

    postnet: 
      _target_: sparkvox.models.codec.BiCodec.modules.feat_decoder.Decoder
      input_channels: 1024
      vocos_dim: 384
      vocos_intermediate_dim: 2048
      vocos_num_layers: 6
      out_channels: 1024
      use_tanh_at_final: False

    d_vector_train_start: 1000

  discriminator:
    _target_: sparkvox.models.codec.BiCodec.modules.discriminator.Discriminator
    _recursive_: true
    clip_grad_val: 1.0
    sample_rate: 32000

    wav_discriminator:
      _target_: sparkvox.models.codec.base.modules.wave_discriminator_dac.WaveDiscriminator
      sample_rate: 32000
      periods: [2, 3, 5, 7, 11]
      bands: [[0.0, 0.1], [0.1, 0.25], [0.25, 0.5], [0.5, 0.75], [0.75, 1.0]]
      stft_params:
        fft_sizes: [2048, 1024, 512]
        hop_sizes: [512, 256, 128]
        win_lengths: [1200, 600, 300]
        window: "hann_window"

  loss_lambdas:
    mse_loss: 1
    ssim_loss: 1
    mel_loss: 15.0
    adv_loss: 1.0
    feature_map_loss: 2.0
    vq_loss: 1.0
    speaker_loss: 1.0

  mel_loss_params:
    sample_rate: 32000
    n_mels: [5, 10, 20, 40, 80, 160, 320]
    window_lengths: [32, 64, 128, 256, 512, 1024, 2048]
    mel_fmin: [0, 0, 0, 0, 0, 0, 0]
    mel_fmax: [null, null, null, null, null, null, null]
    pow: 1.0
    clamp_eps: 1.0e-5

  optimizer:
    gen_grad_clip: 1.0
    gen_optimizer:
      _target_: "torch.optim.AdamW"
      lr: 1.0
      betas: [0.8, 0.9]
    
    gen_lr_scheduler:
      _target_: "sparkvox.utils.scheduler.WarmupLR"
      warmup_step: 1000
      down_step: 500000
      min_lr: 1.0e-5        # this should be the final lr
      max_lr: 1.0e-4 
    
    disc_grad_clip: 1.0
    disc_optimizer: 
      _target_: "torch.optim.AdamW"
      lr: 1.0
      betas: [0.8, 0.9]

    disc_lr_scheduler:
      _target_: "sparkvox.utils.scheduler.WarmupLR"
      warmup_step: 1000
      down_step: 500000
      min_lr: 1.0e-5      # this should be the final lr
      max_lr: 1.0e-4

#===========================| Trainer Configuration |============================#
train:
  trainer:
    devices: -1                           # GPU number, -1 indicates all available GPUs
    num_nodes: 1
    max_epochs: 100000
    max_steps: 3500000       
    val_check_interval: 200              #  Set the int number for iteratons, or an float 0.2 to check 5 times per epoch.
    log_every_n_steps: 100 
    # num_sanity_val_steps: 2
    accelerator: gpu
    strategy: ddp
    precision: 32                         # [32, bf16-mixed ]
    sync_batchnorm: true
    enable_checkpointing: true
    limit_val_batches: 50
    accumulate_grad_batches: 1            # accumulate gradients is not support with manual optimization
    strategy_params:
      find_unused_parameters: true
  
  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: "tensorboard/"         # save tensorboard logs to this directory
    name: ""                         # If it is the empty string then no per-experiment subdirectory is used.
    version: null                    
    log_graph: False                 # log the model graph
    default_hp_metric: False         # log the default metric
    prefix: ""                       # prefix for the log
  
  callbacks:
    model_checkpoint:
      _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: "checkpoints/"
      # monitor: "agg_val_mel_loss"  # used to determine which checkpoint will be saved
      monitor: null
      mode: "min"                  # according to the monitor value, choices=['min', 'max']
      save_top_k: 1                # tok-k best checkpoints will be saved based on monitor and mode
      save_last: True              # always save the last checkpoint
      verbose: true                # print checkpoint information
      every_n_train_steps: 5000    # save checkpoint every n steps
      filename: "{epoch:04d}_{step:06d}"
    
    lr_monitor:
      _target_: pytorch_lightning.callbacks.LearningRateMonitor
      logging_interval: "step"
