#===========================|  Dataset Configuration |==========================#
datasets:
  _target_: sparkvox.models.base.dataloaders.base_datamodule_pl.BaseDataModule
  _recursive_: false
  jsonlfiles:
    "train": "/aifs4su/xinshengwang/data/voxbox/speech/Cantonese/PhoenixTV_subset_and_mix/metadata.jsonl"
    "val": "/aifs4su/xinshengwang/data/voxbox/speech/Cantonese/PhoenixTV_subset_and_mix/metadata.jsonl"

  highpass_cutoff_freq: 40
  sample_rate: 16000 
  segment_duration: 2 # (s)
  max_val_duration: 12 # (s)
  latent_hop_length: 200

  dataloader:
    _target_: sparkvox.models.codec.BigCodec.dataloaders.wav_dataset.WavCodecDataset
    batch_size: 2
    val_batch_size: 1
    num_workers: 8

#===========================|  Model Configuration |============================#
model:
  _target_: sparkvox.models.codec.BigCodec.lightning_models.bigcodec.BigCodecModel
  _recursive_: false
  checkpoint: null    
  ignore_keys: []
  log_interval: 20

  mel:
    sample_rate: 16000
    n_fft: 1024
    win_length: 640
    hop_length: 320
    mel_fmin: 10 
    mel_fmax: null
    num_mels: 128

  generator:
    _target_: sparkvox.models.codec.BigCodec.modules.generator.Generator
    _recursive_: True

    encoder:
      _target_: sparkvox.models.codec.BigCodec.modules.encoder.Encoder
      ngf: 48
      use_rnn: True
      rnn_bidirectional: False
      rnn_num_layers: 2
      up_ratios: [2, 2, 2, 5, 5]
      dilations: [1, 3, 9]
      out_channels: 1024

    decoder:
      _target_: sparkvox.models.codec.BigCodec.modules.decoder.Decoder
      in_channels: 1024
      upsample_initial_channel: 1536
      ngf: 48
      use_rnn: True
      rnn_bidirectional: False
      rnn_num_layers: 2
      up_ratios: [5, 5, 2, 2, 2] # [2, 5, 5, 4]
      dilations: [1, 3, 9]

    quantizer:
      _target_: sparkvox.models.codec.base.quantize.factorized_vector_quantize.FactorizedVectorQuantize
      input_dim: 1024
      codebook_size: 8192
      codebook_dim: 8
      commitment: 0.25
      codebook_loss_weight: 1.0
      decay: 0.99
      threshold_ema_dead_code: 2
      momentum: 0.99

  discriminator:
    _target_: sparkvox.models.codec.BigCodec.modules.discriminator.Discriminator
    _recursive_: true
    clip_grad_val: 1.0

    wav_discriminator:
      _target_: sparkvox.models.codec.BigCodec.modules.mdp.HiFiGANMultiPeriodDiscriminator
      periods: [2, 3, 5, 7, 11]
      max_downsample_channels: 512
      channels: 16
      channel_increasing_factor: 4
      
    spec_discriminator:
      _target_: sparkvox.models.codec.BigCodec.modules.mstft.SpecDiscriminator
      stft_params:
        fft_sizes: [128, 256, 512, 1024, 2048]
        hop_sizes: [32, 64, 128, 256, 512]
        win_lengths: [128, 256, 512, 1024, 2048]
        window: hann_window
      in_channels: 1
      out_channels: 1
      kernel_sizes: [5, 3]
      channels: 32
      max_downsample_channels: 512
      downsample_scales: [2, 2, 2]
      use_weight_norm: True
    
  loss_lambdas:
    mel_loss: 15.0
    feat_match_loss: 1.0
    adv_loss: 1.0
    vq_loss: 1.0

  mel_loss_params:
    sample_rate: 16000
    n_mels: [5, 10, 20, 40, 80, 160, 320]
    window_lengths: [32, 64, 128, 256, 512, 1024, 2048]
    mel_fmin: [0, 0, 0, 0, 0, 0, 0]
    mel_fmax: [null, null, null, null, null, null, null]
    pow: 1.0
    clamp_eps: 1.0e-5

  optimizer:
    gen_grad_clip: 1.0
    gen_optimizer:
      _target_: "torch.optim.AdamW"
      lr: 1.0
      betas: [0.8, 0.9]
    
    gen_lr_scheduler:
      _target_: "sparkvox.utils.scheduler.WarmupLR"
      warmup_step: 1000
      down_step: 500000
      min_lr: 1.0e-5        # this should be the final lr
      max_lr: 1.0e-4 
    
    disc_grad_clip: 1.0
    disc_optimizer: 
      _target_: "torch.optim.AdamW"
      lr: 1.0
      betas: [0.8, 0.9]

    disc_lr_scheduler:
      _target_: "sparkvox.utils.scheduler.WarmupLR"
      warmup_step: 1000
      down_step: 500000
      min_lr: 1.0e-5      # this should be the final lr
      max_lr: 1.0e-4

#===========================| Trainer Configuration |============================#
train:
  trainer:
    devices: 1                           # GPU number, -1 indicates all available GPUs
    num_nodes: 1
    max_epochs: 100000
    max_steps: 500000       
    val_check_interval: 200              #  Set the int number for iteratons, or an float 0.2 to check 5 times per epoch.
    log_every_n_steps: 100 
    # num_sanity_val_steps: 2
    accelerator: gpu
    strategy: ddp
    precision: 32                         # [32, 16-mixed]
    sync_batchnorm: true
    enable_checkpointing: true
    limit_val_batches: 10
    accumulate_grad_batches: 1            # accumulate gradients is not support with manual optimization
    strategy_params:
      find_unused_parameters: true
  
  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: "tensorboard/"         # save tensorboard logs to this directory
    name: ""                         # If it is the empty string then no per-experiment subdirectory is used.
    version: null                    
    log_graph: False                 # log the model graph
    default_hp_metric: False         # log the default metric
    prefix: ""                       # prefix for the log
  
  callbacks:
    model_checkpoint:
      _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: "checkpoints/"
      monitor: "val_acc"           # used to determine which checkpoint will be saved
      mode: "max"                  # according to the monitor value, choices=['min', 'max']
      save_top_k: 1                # tok-k best checkpoints will be saved based on monitor and mode
      save_last: True              # always save the last checkpoint
      verbose: true                # print checkpoint information
      every_n_train_steps: 5000    # save checkpoint every n steps
      filename: "{epoch:04d}_{step:06d}_{val_acc:.2f}"
    
    lr_monitor:
      _target_: pytorch_lightning.callbacks.LearningRateMonitor
      logging_interval: "step"
